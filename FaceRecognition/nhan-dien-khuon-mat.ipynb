{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-13T12:08:30.760005Z",
     "iopub.status.busy": "2025-11-13T12:08:30.759386Z",
     "iopub.status.idle": "2025-11-13T12:08:38.117991Z",
     "shell.execute_reply": "2025-11-13T12:08:38.117171Z",
     "shell.execute_reply.started": "2025-11-13T12:08:30.759976Z"
    },
    "papermill": {
     "duration": 10.737681,
     "end_time": "2025-05-06T07:28:52.053397",
     "exception": false,
     "start_time": "2025-05-06T07:28:41.315716",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import roc_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:08:49.916752Z",
     "iopub.status.busy": "2025-11-13T12:08:49.916041Z",
     "iopub.status.idle": "2025-11-13T12:08:49.921711Z",
     "shell.execute_reply": "2025-11-13T12:08:49.920847Z",
     "shell.execute_reply.started": "2025-11-13T12:08:49.916715Z"
    },
    "papermill": {
     "duration": 0.086373,
     "end_time": "2025-05-06T07:28:52.143781",
     "exception": false,
     "start_time": "2025-05-06T07:28:52.057408",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:27:34.939615Z",
     "iopub.status.busy": "2025-11-13T12:27:34.939248Z",
     "iopub.status.idle": "2025-11-13T12:27:34.996672Z",
     "shell.execute_reply": "2025-11-13T12:27:34.995791Z",
     "shell.execute_reply.started": "2025-11-13T12:27:34.939585Z"
    },
    "papermill": {
     "duration": 204.560402,
     "end_time": "2025-05-06T07:32:16.713882",
     "exception": false,
     "start_time": "2025-05-06T07:28:52.153480",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '/kaggle/input/facedataset2'\n",
    "people = [person for person in os.listdir(dataset_path) \n",
    "          if len(os.listdir(os.path.join(dataset_path, person))) >= 30]\n",
    "person_to_images = {}\n",
    "n_images = []\n",
    "for person in people:\n",
    "    person_dir = os.path.join(dataset_path, person)\n",
    "    images = [os.path.join(person_dir, img) for img in os.listdir(person_dir)]\n",
    "    person_to_images[person] = images\n",
    "    n_images.append(len(images))\n",
    "\n",
    "print(f'Number of people: {len(people)}')\n",
    "print(f'Number of images: {np.sum(n_images):.0f}')\n",
    "print(f'Average: {np.mean(n_images):.1f}')\n",
    "print(f'Min: {np.min(n_images):.0f}')\n",
    "print(f'Max: {np.max(n_images):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:27:40.076298Z",
     "iopub.status.busy": "2025-11-13T12:27:40.076035Z",
     "iopub.status.idle": "2025-11-13T12:27:40.081485Z",
     "shell.execute_reply": "2025-11-13T12:27:40.080800Z",
     "shell.execute_reply.started": "2025-11-13T12:27:40.076281Z"
    },
    "papermill": {
     "duration": 0.010939,
     "end_time": "2025-05-06T07:32:16.728446",
     "exception": false,
     "start_time": "2025-05-06T07:32:16.717507",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "label_to_index = {person: idx for idx, person in enumerate(people)}\n",
    "num_classes = len(label_to_index)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:31:39.899499Z",
     "iopub.status.busy": "2025-11-13T12:31:39.898825Z",
     "iopub.status.idle": "2025-11-13T12:31:39.904650Z",
     "shell.execute_reply": "2025-11-13T12:31:39.903792Z",
     "shell.execute_reply.started": "2025-11-13T12:31:39.899473Z"
    },
    "papermill": {
     "duration": 0.009331,
     "end_time": "2025-05-06T07:32:16.741381",
     "exception": false,
     "start_time": "2025-05-06T07:32:16.732050",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ArcFaceDataset(Dataset):\n",
    "    def __init__(self, person_to_images, label_to_index, transform=None):\n",
    "        self.image_label_pairs = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for person, image_paths in person_to_images.items():\n",
    "            label = label_to_index[person]\n",
    "            for path in image_paths:\n",
    "                self.image_label_pairs.append((path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_label_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.image_label_pairs[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:31:45.335889Z",
     "iopub.status.busy": "2025-11-13T12:31:45.335632Z",
     "iopub.status.idle": "2025-11-13T12:31:45.340895Z",
     "shell.execute_reply": "2025-11-13T12:31:45.340125Z",
     "shell.execute_reply.started": "2025-11-13T12:31:45.335873Z"
    },
    "papermill": {
     "duration": 0.049577,
     "end_time": "2025-05-06T07:32:16.794619",
     "exception": false,
     "start_time": "2025-05-06T07:32:16.745042",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = ArcFaceDataset(person_to_images, label_to_index, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:32:25.735284Z",
     "iopub.status.busy": "2025-11-13T12:32:25.734795Z",
     "iopub.status.idle": "2025-11-13T12:32:25.745660Z",
     "shell.execute_reply": "2025-11-13T12:32:25.744987Z",
     "shell.execute_reply.started": "2025-11-13T12:32:25.735260Z"
    },
    "papermill": {
     "duration": 17.305671,
     "end_time": "2025-05-06T07:32:34.110053",
     "exception": false,
     "start_time": "2025-05-06T07:32:16.804382",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lwf_dataset_path = '/kaggle/input/facedataset2'\n",
    "lwf_people = [person for person in os.listdir(lwf_dataset_path) \n",
    "          if len(os.listdir(os.path.join(lwf_dataset_path, person))) >= 2]\n",
    "lwf_person_to_images = {}\n",
    "lwf_n_images = []\n",
    "\n",
    "for person in lwf_people:\n",
    "    person_dir = os.path.join(lwf_dataset_path, person)\n",
    "    images = [os.path.join(person_dir, img) for img in os.listdir(person_dir)]\n",
    "    lwf_person_to_images[person] = images\n",
    "    lwf_n_images.append(len(images))\n",
    "\n",
    "print(f'Number of people: {len(lwf_people)}')\n",
    "print(f'Number of images: {np.sum(lwf_n_images):.0f}')\n",
    "print(f'Average: {np.mean(lwf_n_images):.1f}')\n",
    "print(f'Min: {np.min(lwf_n_images):.0f}')\n",
    "print(f'Max: {np.max(lwf_n_images):.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.003952,
     "end_time": "2025-05-06T07:32:34.118291",
     "exception": false,
     "start_time": "2025-05-06T07:32:34.114339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Danh gia model sau khi huan luyen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:32:42.629076Z",
     "iopub.status.busy": "2025-11-13T12:32:42.628807Z",
     "iopub.status.idle": "2025-11-13T12:32:42.651108Z",
     "shell.execute_reply": "2025-11-13T12:32:42.650321Z",
     "shell.execute_reply.started": "2025-11-13T12:32:42.629055Z"
    },
    "papermill": {
     "duration": 0.027619,
     "end_time": "2025-05-06T07:32:34.149769",
     "exception": false,
     "start_time": "2025-05-06T07:32:34.122150",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_verification_pairs(person_to_images, num_pairs=6000):\n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "\n",
    "    people = list(person_to_images.keys())\n",
    "\n",
    "    while len(positive_pairs) < num_pairs // 2:\n",
    "        person = random.choice(people)\n",
    "        images = person_to_images[person]\n",
    "        if len(images) >= 2:\n",
    "            pair = random.sample(images, 2)\n",
    "            positive_pairs.append((pair[0], pair[1], 1))\n",
    "\n",
    "    while len(negative_pairs) < num_pairs // 2:\n",
    "        person1, person2 = random.sample(people, 2)\n",
    "        img1 = random.choice(person_to_images[person1])\n",
    "        img2 = random.choice(person_to_images[person2])\n",
    "        negative_pairs.append((img1, img2, 0))\n",
    "\n",
    "    return positive_pairs + negative_pairs\n",
    "\n",
    "pairs = generate_verification_pairs(lwf_person_to_images)\n",
    "random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:32:46.916144Z",
     "iopub.status.busy": "2025-11-13T12:32:46.915883Z",
     "iopub.status.idle": "2025-11-13T12:32:46.922143Z",
     "shell.execute_reply": "2025-11-13T12:32:46.921575Z",
     "shell.execute_reply.started": "2025-11-13T12:32:46.916126Z"
    },
    "papermill": {
     "duration": 0.010357,
     "end_time": "2025-05-06T07:32:34.163859",
     "exception": false,
     "start_time": "2025-05-06T07:32:34.153502",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "class LFWEvalDataset(Dataset):\n",
    "    def __init__(self, pairs, transform=None):\n",
    "        self.pairs = pairs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path1, path2, label = self.pairs[idx]\n",
    "        img1 = Image.open(path1).convert('RGB')\n",
    "        img2 = Image.open(path2).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, label\n",
    "\n",
    "lfw_eval_dataset = LFWEvalDataset(pairs, transform=transform)\n",
    "lfw_loader = DataLoader(lfw_eval_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:32:50.761346Z",
     "iopub.status.busy": "2025-11-13T12:32:50.761073Z",
     "iopub.status.idle": "2025-11-13T12:32:50.766807Z",
     "shell.execute_reply": "2025-11-13T12:32:50.766147Z",
     "shell.execute_reply.started": "2025-11-13T12:32:50.761325Z"
    },
    "papermill": {
     "duration": 0.009454,
     "end_time": "2025-05-06T07:32:34.176622",
     "exception": false,
     "start_time": "2025-05-06T07:32:34.167168",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_embeddings(model, dataloader, device):\n",
    "    model.eval()\n",
    "    emb1_list, emb2_list, labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img1, img2, label in tqdm(dataloader, desc=\"Generating embeddings\"):\n",
    "            img1 = img1.to(device)\n",
    "            img2 = img2.to(device)\n",
    "\n",
    "            emb1 = model(img1)\n",
    "            emb2 = model(img2)\n",
    "\n",
    "            emb1_list.append(emb1.cpu())\n",
    "            emb2_list.append(emb2.cpu())\n",
    "            labels.append(label)\n",
    "\n",
    "    return (\n",
    "        torch.cat(emb1_list),\n",
    "        torch.cat(emb2_list),\n",
    "        torch.cat(labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:32:57.830345Z",
     "iopub.status.busy": "2025-11-13T12:32:57.829757Z",
     "iopub.status.idle": "2025-11-13T12:32:57.835343Z",
     "shell.execute_reply": "2025-11-13T12:32:57.834413Z",
     "shell.execute_reply.started": "2025-11-13T12:32:57.830320Z"
    },
    "papermill": {
     "duration": 0.008727,
     "end_time": "2025-05-06T07:32:34.188654",
     "exception": false,
     "start_time": "2025-05-06T07:32:34.179927",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(emb1, emb2, labels):\n",
    "    \n",
    "    emb1 = F.normalize(emb1, dim=1)\n",
    "    emb2 = F.normalize(emb2, dim=1)\n",
    "    distances = torch.norm(emb1 - emb2, dim=1).numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(labels, -distances)  \n",
    "\n",
    "    best_acc, best_thresh = 0, 0\n",
    "    for thresh in thresholds:\n",
    "        preds = distances < -thresh  \n",
    "        acc = accuracy_score(labels, preds)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_thresh = -thresh \n",
    "\n",
    "    return {\n",
    "        'accuracy': best_acc,\n",
    "        'threshold': best_thresh,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:33:01.968531Z",
     "iopub.status.busy": "2025-11-13T12:33:01.967956Z",
     "iopub.status.idle": "2025-11-13T12:33:01.973371Z",
     "shell.execute_reply": "2025-11-13T12:33:01.972668Z",
     "shell.execute_reply.started": "2025-11-13T12:33:01.968492Z"
    },
    "papermill": {
     "duration": 0.008594,
     "end_time": "2025-05-06T07:32:34.206781",
     "exception": false,
     "start_time": "2025-05-06T07:32:34.198187",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ArcFaceModel(nn.Module):\n",
    "    def __init__(self, embedding_size=512, num_classes=num_classes):\n",
    "        super(ArcFaceModel, self).__init__()\n",
    "        self.backbone = resnet50(weights='DEFAULT')\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, embedding_size)\n",
    "        self.backbone_bn = nn.BatchNorm1d(embedding_size)\n",
    "        self.backbone_bn.bias.requires_grad_(False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.backbone_bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:33:05.466960Z",
     "iopub.status.busy": "2025-11-13T12:33:05.466352Z",
     "iopub.status.idle": "2025-11-13T12:33:05.474911Z",
     "shell.execute_reply": "2025-11-13T12:33:05.474226Z",
     "shell.execute_reply.started": "2025-11-13T12:33:05.466929Z"
    },
    "papermill": {
     "duration": 0.010878,
     "end_time": "2025-05-06T07:32:34.227279",
     "exception": false,
     "start_time": "2025-05-06T07:32:34.216401",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        one_hot = torch.zeros(cosine.size(), device=input.device)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1.0)\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:33:10.508360Z",
     "iopub.status.busy": "2025-11-13T12:33:10.508116Z",
     "iopub.status.idle": "2025-11-13T12:33:11.737349Z",
     "shell.execute_reply": "2025-11-13T12:33:11.736762Z",
     "shell.execute_reply.started": "2025-11-13T12:33:10.508344Z"
    },
    "papermill": {
     "duration": 1.507723,
     "end_time": "2025-05-06T07:32:35.744542",
     "exception": false,
     "start_time": "2025-05-06T07:32:34.236819",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = ArcFaceModel(embedding_size=128, num_classes=num_classes).to(device)\n",
    "metric_fc = ArcMarginProduct(128, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(list(model.parameters()) + list(metric_fc.parameters()), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.3)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:33:22.895060Z",
     "iopub.status.busy": "2025-11-13T12:33:22.894786Z",
     "iopub.status.idle": "2025-11-13T13:03:23.325134Z",
     "shell.execute_reply": "2025-11-13T13:03:23.324485Z",
     "shell.execute_reply.started": "2025-11-13T12:33:22.895039Z"
    },
    "papermill": {
     "duration": 41001.461103,
     "end_time": "2025-05-06T18:55:57.209864",
     "exception": false,
     "start_time": "2025-05-06T07:32:35.748761",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "thresh_history = []\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    metric_fc.train()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        embeddings = model(images)  # (B, 512)\n",
    "        logits = metric_fc(embeddings, labels)  # (B, num_classes)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    emb1, emb2, labels = get_embeddings(model, lfw_loader, device)\n",
    "    results = evaluate(emb1, emb2, labels)\n",
    "    acc_history.append(results['accuracy'])\n",
    "    thresh_history.append(results['threshold'])\n",
    "\n",
    "    if results['accuracy'] > acc_history[best_epoch]:\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'best_arcface_model.pth')\n",
    "\n",
    "    print(f\"Loss: {avg_loss:.4f}, Accuracy: {results['accuracy']:.4f}, Threshold: {results['threshold']:.4f}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T13:33:35.969167Z",
     "iopub.status.busy": "2025-11-13T13:33:35.968874Z",
     "iopub.status.idle": "2025-11-13T13:33:35.973660Z",
     "shell.execute_reply": "2025-11-13T13:33:35.972691Z",
     "shell.execute_reply.started": "2025-11-13T13:33:35.969147Z"
    },
    "papermill": {
     "duration": 0.982646,
     "end_time": "2025-05-06T18:55:59.334893",
     "exception": false,
     "start_time": "2025-05-06T18:55:58.352247",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Best epoch: {best_epoch + 1}\")\n",
    "print(f\"Loss: {loss_history[best_epoch]:.4f}\")\n",
    "print(f\"Accuracy: {acc_history[best_epoch]:.4f}\")\n",
    "print(f\"Threshold: {thresh_history[best_epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T13:33:45.319394Z",
     "iopub.status.busy": "2025-11-13T13:33:45.319127Z",
     "iopub.status.idle": "2025-11-13T13:33:45.735057Z",
     "shell.execute_reply": "2025-11-13T13:33:45.734449Z",
     "shell.execute_reply.started": "2025-11-13T13:33:45.319373Z"
    },
    "papermill": {
     "duration": 1.696245,
     "end_time": "2025-05-06T18:56:02.023700",
     "exception": false,
     "start_time": "2025-05-06T18:56:00.327455",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "#  Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(loss_history)\n",
    "plt.scatter(best_epoch, loss_history[best_epoch], color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "#  Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(acc_history, color='green')\n",
    "plt.scatter(best_epoch, acc_history[best_epoch], color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Evaluation Accuracy')\n",
    "\n",
    "# Threshold\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(thresh_history, color='orange')\n",
    "plt.scatter(best_epoch, thresh_history[best_epoch], color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Threshold')\n",
    "plt.title('Best Threshold')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8728126,
     "sourceId": 13718866,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41249.044894,
   "end_time": "2025-05-06T18:56:05.914869",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-06T07:28:36.869975",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
